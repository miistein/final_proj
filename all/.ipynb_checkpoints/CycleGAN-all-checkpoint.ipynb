{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND']='tensorflow' # can choose theano, tensorflow, cntk\n",
    "#os.environ['THEANO_FLAGS']='floatX=float32,device=cuda,optimizer=fast_run,dnn.library_path=/usr/lib'\n",
    "#os.environ['THEANO_FLAGS']='floatX=float32,device=cuda,optimizer=fast_compile,dnn.library_path=/usr/lib'\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"  # specify which GPU(s) to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, ZeroPadding2D, BatchNormalization, Input, Dropout\n",
    "from keras.layers import Conv2DTranspose, Reshape, Activation, Cropping2D, Flatten\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import relu\n",
    "from keras.initializers import RandomNormal\n",
    "\n",
    "# extra dependency, install with: pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
    "#from keras_contrib.callbacks import CyclicLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "channel_axis=-1\n",
    "channel_first = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose folder. I chose mix for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of william blake images\n",
    "numBlakeImages = !ls -l ../dataset_williamblake/all | egrep -c '^-'\n",
    "numBlakeImages = int(numBlakeImages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paintings_folder = '../dataset_paintings/paintings/*/*.png'\n",
    "williamblake_folder = '../dataset_williamblake/all' +'/*.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define some hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color\n",
    "nc_in = 3\n",
    "nc_out = 3\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "use_lsgan = True\n",
    "lambdavar = 10 if use_lsgan else 100\n",
    "\n",
    "# number of gpus\n",
    "num_gpus = 1\n",
    "# dropout rate\n",
    "dropoutRate = 0.4\n",
    "# ideally: scale the william blake image to the image size during loading and have the final image as 512x512\n",
    "# but since everything should lose no information going down to 512x512 this is fine\n",
    "loadSize = 128*2\n",
    "imageSize = 128*2\n",
    "# set the batch size to a quarter of the william blake images. There should be no more than a hundred. If there are,\n",
    "# it is recommended to adjust the batch size to be a percentage of the number of images.\n",
    "# since mine is exactly 71, use batch size of 71/3\n",
    "iters = 3\n",
    "batchSize = numBlakeImages // iters\n",
    "epochs = 100\n",
    "iterPerEpoch = numBlakeImages // batchSize\n",
    "# new parameter:\n",
    "iters_generator = 2\n",
    "\n",
    "# cyclic learning rate scheme. See https://github.com/bckenstler/CLR for details.\n",
    "lrD = 2e-4\n",
    "lrG = 2e-4\n",
    "momentum = .9\n",
    "\n",
    "# according to https://github.com/bckenstler/CLR step size should be (2-8) x (training iterations in epoch)\n",
    "#clrD = CyclicLR(base_lr=lrD, max_lr=3*lrD,\n",
    "#                        step_size=8*iterPerEpoch)\n",
    "#clrG = CyclicLR(base_lr=lrG, max_lr=3*lrG,\n",
    "#                        step_size=8*iterPerEpoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define network with KERAS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights initializations\n",
    "# bias are initailized as 0\n",
    "def __conv_init(a):\n",
    "    print(\"conv_init\", a)\n",
    "    k = RandomNormal(0, 0.02)(a) # for convolution kernel\n",
    "    k.conv_weight = True\n",
    "    return k\n",
    "conv_init = RandomNormal(0, 0.02)\n",
    "gamma_init = RandomNormal(1., 0.02) # for batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic discriminator\n",
    "def conv2d(f, *a, **k):\n",
    "    return Conv2D(f, kernel_initializer = conv_init, *a, **k)\n",
    "def batchnorm():\n",
    "    return BatchNormalization(momentum=0.9, axis=channel_axis, epsilon=1.01e-5,\n",
    "                                   gamma_initializer = gamma_init)\n",
    "def BASIC_D(nc_in, ndf, max_layers=3, use_sigmoid=True):\n",
    "    \"\"\"DCGAN_D(nc, ndf, max_layers=3)\n",
    "       nc: channels\n",
    "       ndf: filters of the first layer\n",
    "       max_layers: max hidden layers\n",
    "    \"\"\"    \n",
    "    if channel_first:\n",
    "        input_a =  Input(shape=(nc_in, None, None))\n",
    "    else:\n",
    "        input_a = Input(shape=(None, None, nc_in))\n",
    "    _ = input_a\n",
    "    _ = conv2d(ndf, kernel_size=4, strides=2, padding=\"same\", name = 'First') (_)\n",
    "    _ = LeakyReLU(alpha=0.2)(_)\n",
    "    \n",
    "    for layer in range(1, max_layers):        \n",
    "        out_feat = ndf * min(2**layer, 8)\n",
    "        _ = conv2d(out_feat, kernel_size=4, strides=2, padding=\"same\", \n",
    "                   use_bias=False, name = 'pyramid.{0}'.format(layer)             \n",
    "                        ) (_)\n",
    "        _ = batchnorm()(_, training=1)        \n",
    "        _ = LeakyReLU(alpha=0.2)(_)\n",
    "    \n",
    "    out_feat = ndf*min(2**max_layers, 8)\n",
    "    _ = ZeroPadding2D(1)(_)\n",
    "    _ = conv2d(out_feat, kernel_size=4,  use_bias=False, name = 'pyramid_last') (_)\n",
    "    _ = batchnorm()(_, training=1)\n",
    "    _ = LeakyReLU(alpha=0.2)(_)\n",
    "    \n",
    "    # final layer\n",
    "    _ = ZeroPadding2D(1)(_)\n",
    "    _ = conv2d(1, kernel_size=4, name = 'final'.format(out_feat, 1), \n",
    "               activation = \"sigmoid\" if use_sigmoid else None) (_)    \n",
    "    return Model(inputs=[input_a], outputs=_,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNET_G(isize, nc_in=3, nc_out=3, ngf=64, fixed_input_size=True):    \n",
    "    max_nf = 8*ngf    \n",
    "    def block(x, s, nf_in, use_batchnorm=True, nf_out=None, nf_next=None):\n",
    "        # print(\"block\",x,s,nf_in, use_batchnorm, nf_out, nf_next)\n",
    "        assert s>=2 and s%2==0\n",
    "        if nf_next is None:\n",
    "            nf_next = min(nf_in*2, max_nf)\n",
    "        if nf_out is None:\n",
    "            nf_out = nf_in\n",
    "        x = conv2d(nf_next, kernel_size=4, strides=2, use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\", name = 'conv_{0}'.format(s)) (x)\n",
    "        if s>2:\n",
    "            if use_batchnorm:\n",
    "                x = batchnorm()(x, training=1)\n",
    "            x2 = LeakyReLU(alpha=0.2)(x)\n",
    "            x2 = block(x2, s//2, nf_next)\n",
    "            x = Concatenate(axis=channel_axis)([x, x2])            \n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2DTranspose(nf_out, kernel_size=4, strides=2, use_bias=not use_batchnorm,\n",
    "                            kernel_initializer = conv_init,          \n",
    "                            name = 'convt.{0}'.format(s))(x)        \n",
    "        x = Cropping2D(1)(x)\n",
    "        if use_batchnorm:\n",
    "            x = batchnorm()(x, training=1)\n",
    "        if s <=8:\n",
    "            x = Dropout(dropoutRate)(x, training=1)\n",
    "        return x\n",
    "    \n",
    "    s = isize if fixed_input_size else None\n",
    "    if channel_first:\n",
    "        _ = inputs = Input(shape=(nc_in, s, s))\n",
    "    else:\n",
    "        _ = inputs = Input(shape=(s, s, nc_in))        \n",
    "    _ = block(_, isize, nc_in, False, nf_out=nc_out, nf_next=ngf)\n",
    "    _ = Activation('tanh')(_)\n",
    "    return Model(inputs=inputs, outputs=[_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "First (Conv2D)               (None, None, None, 64)    3136      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "pyramid.1 (Conv2D)           (None, None, None, 128)   131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "pyramid.2 (Conv2D)           (None, None, None, 256)   524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "pyramid_last (Conv2D)        (None, None, None, 512)   2097152   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "final (Conv2D)               (None, None, None, 1)     8193      \n",
      "=================================================================\n",
      "Total params: 2,767,425\n",
      "Trainable params: 2,765,633\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "netDA = BASIC_D(nc_in, ndf, use_sigmoid = not use_lsgan)\n",
    "netDB = BASIC_D(nc_out, ndf, use_sigmoid = not use_lsgan)\n",
    "netDA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "using multiple gpus\n",
      "not using multiple gpu\n",
      "using multiple gpus\n",
      "not using multiple gpu\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_256 (Conv2D)               (None, 128, 128, 64) 3136        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 128, 128, 64) 0           conv_256[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_128 (Conv2D)               (None, 64, 64, 128)  131072      leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64, 64, 128)  512         conv_128[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 64, 64, 128)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_64 (Conv2D)                (None, 32, 32, 256)  524288      leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 256)  1024        conv_64[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 32, 32, 256)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_32 (Conv2D)                (None, 16, 16, 512)  2097152     leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 512)  2048        conv_32[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 16, 16, 512)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 8, 8, 512)    4194304     leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8, 8, 512)    2048        conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 8, 8, 512)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 4, 4, 512)    4194304     leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 4, 4, 512)    2048        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 4, 4, 512)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 2, 2, 512)    4194304     leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 2, 2, 512)    2048        conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 2, 2, 512)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 1, 1, 512)    4194816     leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1, 1, 512)    0           conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convt.2 (Conv2DTranspose)       (None, 4, 4, 512)    4194304     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_9 (Cropping2D)       (None, 2, 2, 512)    0           convt.2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 2, 2, 512)    2048        cropping2d_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 2, 2, 512)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 2, 2, 1024)   0           batch_normalization_25[0][0]     \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 2, 2, 1024)   0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.4 (Conv2DTranspose)       (None, 6, 6, 512)    8388608     activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_10 (Cropping2D)      (None, 4, 4, 512)    0           convt.4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 4, 4, 512)    2048        cropping2d_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 4, 4, 512)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 4, 4, 1024)   0           batch_normalization_24[0][0]     \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 4, 1024)   0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "convt.8 (Conv2DTranspose)       (None, 10, 10, 512)  8388608     activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_11 (Cropping2D)      (None, 8, 8, 512)    0           convt.8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 512)    2048        cropping2d_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 8, 8, 512)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 8, 8, 1024)   0           batch_normalization_23[0][0]     \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 1024)   0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "convt.16 (Conv2DTranspose)      (None, 18, 18, 512)  8388608     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_12 (Cropping2D)      (None, 16, 16, 512)  0           convt.16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 512)  2048        cropping2d_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 16, 16, 1024) 0           batch_normalization_22[0][0]     \n",
      "                                                                 batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 1024) 0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "convt.32 (Conv2DTranspose)      (None, 34, 34, 256)  4194304     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_13 (Cropping2D)      (None, 32, 32, 256)  0           convt.32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 32, 256)  1024        cropping2d_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 32, 32, 512)  0           batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 512)  0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "convt.64 (Conv2DTranspose)      (None, 66, 66, 128)  1048576     activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_14 (Cropping2D)      (None, 64, 64, 128)  0           convt.64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 64, 64, 128)  512         cropping2d_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 64, 64, 256)  0           batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 64, 64, 256)  0           concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "convt.128 (Conv2DTranspose)     (None, 130, 130, 64) 262144      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_15 (Cropping2D)      (None, 128, 128, 64) 0           convt.128[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 128, 128, 64) 256         cropping2d_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 128, 128, 128 0           conv_256[0][0]                   \n",
      "                                                                 batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 128, 128, 128 0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "convt.256 (Conv2DTranspose)     (None, 258, 258, 3)  6147        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_16 (Cropping2D)      (None, 256, 256, 3)  0           convt.256[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 256, 256, 3)  0           cropping2d_16[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 54,424,387\n",
      "Trainable params: 54,414,531\n",
      "Non-trainable params: 9,856\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "\n",
    "# can use a multiple gpu model, but tends to be slower.\n",
    "netGB = UNET_G(imageSize, nc_in, nc_out, ngf)\n",
    "try:\n",
    "    print('using multiple gpus')\n",
    "    netGB = multi_gpu_model(netGB,gpus=num_gpus)\n",
    "except:\n",
    "    print('not using multiple gpu')\n",
    "\n",
    "netGA = UNET_G(imageSize, nc_out, nc_in, ngf)\n",
    "try:\n",
    "    print('using multiple gpus')\n",
    "    netGA = multi_gpu_model(netGA,gpus=num_gpus)\n",
    "except:\n",
    "    print('not using multiple gpu')\n",
    "    \n",
    "#SVG(model_to_dot(netG, show_shapes=True).create(prog='dot', format='svg'))\n",
    "netGA.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop, SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_lsgan:\n",
    "    loss_fn = lambda output, target : K.mean(K.abs(K.square(output-target)))\n",
    "else:\n",
    "    loss_fn = lambda output, target : -K.mean(K.log(output+1e-12)*target+K.log(1-output+1e-12)*(1-target))\n",
    "\n",
    "def cycle_variables(netG1, netG2):\n",
    "    real_input = netG1.inputs[0]\n",
    "    fake_output = netG1.outputs[0]\n",
    "    rec_input = netG2([fake_output])\n",
    "    fn_generate = K.function([real_input], [fake_output, rec_input])\n",
    "    return real_input, fake_output, rec_input, fn_generate\n",
    "\n",
    "real_A, fake_B, rec_A, cycleA_generate = cycle_variables(netGB, netGA)\n",
    "real_B, fake_A, rec_B, cycleB_generate = cycle_variables(netGA, netGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_loss(netD, real, fake, rec):\n",
    "    output_real = netD([real])\n",
    "    output_fake = netD([fake])\n",
    "    loss_D_real = loss_fn(output_real, K.ones_like(output_real))\n",
    "    loss_D_fake = loss_fn(output_fake, K.zeros_like(output_fake))\n",
    "    loss_G = loss_fn(output_fake, K.ones_like(output_fake))\n",
    "    loss_D = loss_D_real+loss_D_fake\n",
    "    loss_cyc = K.mean(K.abs(rec-real))\n",
    "    return loss_D, loss_G, loss_cyc\n",
    "\n",
    "loss_DA, loss_GA, loss_cycA = D_loss(netDA, real_A, fake_A, rec_A)\n",
    "loss_DB, loss_GB, loss_cycB = D_loss(netDB, real_B, fake_B, rec_B)\n",
    "loss_cyc = loss_cycA+loss_cycB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_G = loss_GA+loss_GB+lambdavar*loss_cyc\n",
    "loss_D = loss_DA+loss_DB\n",
    "\n",
    "weightsD = netDA.trainable_weights + netDB.trainable_weights\n",
    "weightsG = netGA.trainable_weights + netGB.trainable_weights\n",
    "\n",
    "training_updates = SGD(lr=lrG, momentum=momentum,nesterov=True).get_updates(weightsD,[],loss_D)\n",
    "netD_train = K.function([real_A, real_B],[loss_DA/2, loss_DB/2], training_updates)\n",
    "training_updates = SGD(lr=lrD, momentum=momentum,nesterov=True).get_updates(weightsG,[], loss_G)\n",
    "netG_train = K.function([real_A, real_B], [loss_GA, loss_GB, loss_cyc], training_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "from random import randint, shuffle\n",
    "\n",
    "def load_data(file_pattern):\n",
    "    return glob.glob(file_pattern)\n",
    "\n",
    "def read_image(fn, is_input=False, grayscale_input=True):\n",
    "    im = Image.open(fn).convert('RGB')\n",
    "    im = im.resize( (loadSize, loadSize), Image.BILINEAR )\n",
    "    arr = np.array(im).astype(float)\n",
    "    arr=arr/255*2-1\n",
    "    \n",
    "    w1,w2 = (loadSize-imageSize)//2,(loadSize+imageSize)//2\n",
    "    h1,h2 = w1,w2\n",
    "    img = arr[h1:h2, w1:w2, :]\n",
    "        \n",
    "    # grayscale input\n",
    "    if is_input and grayscale_input:\n",
    "        img = np.maximum(np.maximum(img[:,:,2],img[:, :,1]), img[:,:,0])\n",
    "        img = np.broadcast_to(img[...,None],img.shape+(3,))\n",
    "        \n",
    "    if channel_first:        \n",
    "        img = np.moveaxis(img, 2, 0)\n",
    "        \n",
    "    return img\n",
    "\n",
    "train_A = load_data(paintings_folder)\n",
    "train_B = load_data(williamblake_folder)\n",
    "\n",
    "assert len(train_A) and len(train_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch(data, batchsize):\n",
    "    length = len(data)\n",
    "    epoch = i = 0\n",
    "    tmpsize = None    \n",
    "    while True:\n",
    "        size = tmpsize if tmpsize else batchsize\n",
    "        if i+size > length:\n",
    "            shuffle(data)\n",
    "            i = 0\n",
    "            epoch+=1        \n",
    "        rtn = [read_image(data[j]) for j in range(i,i+size)]\n",
    "        i+=size\n",
    "        tmpsize = yield epoch, np.float32(rtn)       \n",
    "\n",
    "def minibatchAB(dataA, dataB, batchsize):\n",
    "    batchA=minibatch(dataA, batchsize)\n",
    "    batchB=minibatch(dataB, batchsize)\n",
    "    tmpsize = None    \n",
    "    while True:        \n",
    "        ep1, A = batchA.send(tmpsize)\n",
    "        ep2, B = batchB.send(tmpsize)\n",
    "        tmpsize = yield max(ep1, ep2), A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "def showX(X, rows=1):\n",
    "    #assert X.shape[0]%rows == 0\n",
    "    int_X = ( (X+1)/2*255).clip(0,255).astype('uint8')\n",
    "    if channel_first:\n",
    "        int_X = np.moveaxis(int_X.reshape(-1,3,imageSize,imageSize), 1, 3)\n",
    "    else:\n",
    "        int_X = int_X.reshape(-1,imageSize,imageSize, 3)\n",
    "    int_X = int_X.reshape(rows, -1, imageSize, imageSize,3).swapaxes(1,2).reshape(rows*imageSize,-1, 3)\n",
    "    display(Image.fromarray(int_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_batch = minibatchAB(train_A, train_B, 5)\n",
    "\n",
    "# _, A, B = next(train_batch)\n",
    "# showX(A)\n",
    "# showX(B)\n",
    "#del train_batch, A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showG(A,B):\n",
    "    assert A.shape==B.shape\n",
    "    def G(fn_generate, X):\n",
    "        r = np.array([fn_generate([X[i:i+1]]) for i in range(X.shape[0])])\n",
    "        return r.swapaxes(0,1)[:,:,0]        \n",
    "    rA = G(cycleA_generate, A)\n",
    "    rB = G(cycleB_generate, B)\n",
    "    arr = np.concatenate([A,B,rA[0],rB[0],rA[1],rB[1]])\n",
    "    showX(arr, 3)\n",
    "    \n",
    "def showGen(A):\n",
    "    def G(fn_generate, X):\n",
    "        r = np.array([fn_generate([X[i:i+1]]) for i in range(X.shape[0])])\n",
    "        return r.swapaxes(0,1)[:,:,0]        \n",
    "    rA = G(cycleA_generate, A)\n",
    "    print('input image (may not look exactly like the original due to preprocessing)')\n",
    "    # inp image\n",
    "    showX(rA[1])\n",
    "    print('output of the generator')\n",
    "    showX(rA[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "def save_models():\n",
    "    t = 'D'\n",
    "    for i,model in enumerate([netDA,netDB]):\n",
    "        # serialize model to JSON\n",
    "        model_json = model.to_json()\n",
    "        with open(\"model\" + t + str(i) +\".json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        # serialize weights to HDF5\n",
    "        model.save_weights(\"model\" + t + str(i) +\".h5\")\n",
    "        print(\"Saved D model to disk\")\n",
    "\n",
    "    t = 'G'\n",
    "    for i,model in enumerate([netGA,netGB]):\n",
    "        # serialize model to JSON\n",
    "        model_json = model.to_json()\n",
    "        with open(\"model\" + t + str(i) +\".json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        # serialize weights to HDF5\n",
    "        model.save_weights(\"model\" + t + str(i) +\".h5\")\n",
    "        print(\"Saved G model to disk\")\n",
    "\n",
    "        \n",
    "def load_weight(i,char,net):\n",
    "    net.load_weights(\"model\" + char + str(i) +\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoints_exist():\n",
    "    for i in range(1):\n",
    "        if os.path.exists('modelD0.h5'.format(i)) and os.path.exists('modelG{}.h5'.format(i)):\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from .h5 files\n"
     ]
    }
   ],
   "source": [
    "if checkpoints_exist():\n",
    "    t = 'D'\n",
    "    for i,model in enumerate([netDA,netDB]):\n",
    "        load_weight(i,t,model)\n",
    "    t = 'G'\n",
    "    for i,model in enumerate([netGA,netGB]):\n",
    "        load_weight(i,t,model)\n",
    "\n",
    "#     for i in range(10):\n",
    "#         _, A, B = train_batch.send(2)\n",
    "    print('loaded from .h5 files')\n",
    "#     showG(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "def train(epochs):\n",
    "    import time\n",
    "    from IPython.display import clear_output\n",
    "\n",
    "    errCyc_sum = errGA_sum = errGB_sum = errDA_sum = errDB_sum = 0\n",
    "\n",
    "    display_epochs = 100\n",
    "    save_epochs = 400\n",
    "    train_batch = minibatchAB(train_A, train_B, batchSize)\n",
    "\n",
    "    for epoch in range(epochs): \n",
    "        for niter in range(iters):\n",
    "            _, A, B = next(train_batch)        \n",
    "            errDA, errDB  = netD_train([A, B])\n",
    "            errDA_sum += errDA / iters\n",
    "            errDB_sum += errDB / iters\n",
    "\n",
    "            for i in range(2):\n",
    "                errGA, errGB, errCyc = netG_train([A, B])\n",
    "                errGA_sum += errGA / (2*iters)\n",
    "                errGB_sum += errGB / (2*iters)\n",
    "                errCyc_sum += errCyc / (2*iters)\n",
    "                \n",
    "        # check if loss is converging and print current output\n",
    "        if epoch%display_epochs==0:\n",
    "                #if gen_iterations%(5*display_epochs)==0:\n",
    "                clear_output()\n",
    "                print('[%dth epoch] out of [%d epochs] Loss_D: %f %f Loss_G: %f %f loss_cyc'\n",
    "                % (epoch, epochs, errDB_sum/display_epochs,\n",
    "                   errGA_sum/display_epochs, errGB_sum/display_epochs, \n",
    "                   errCyc_sum/display_epochs))\n",
    "                _, A, B = train_batch.send(4)\n",
    "                showG(A,B)\n",
    "                errCyc_sum = errGA_sum = errGB_sum = errDA_sum = errDB_sum = 0\n",
    "\n",
    "        if epoch%save_epochs==0 and epoch!=0:\n",
    "            print('saving models every {} iterations (h5 and json)'.format(save_epochs))\n",
    "            save_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displayed in the order of: image A, image B, generated image\n",
    "- To download results, should be able to right click (or shift+right click) save image\n",
    "\n",
    "## The model will always create a set image for a given input. The B does not matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get results\n",
    "if TRAIN:\n",
    "    train(epochs)\n",
    "    save_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "def showGen(A):\n",
    "    def G(fn_generate, X):\n",
    "        r = np.array([fn_generate([X[i:i+1]]) for i in range(X.shape[0])])\n",
    "        return r.swapaxes(0,1)[:,:,0]        \n",
    "    rA = G(cycleA_generate, A)\n",
    "    print('input image (may not look exactly like the original due to preprocessing)')\n",
    "    # inp image\n",
    "    showX(rA[1])\n",
    "    print('output of the generator')\n",
    "    showX(rA[0])\n",
    "    \n",
    "def generate(gen_A,n_generate):    \n",
    "    print(len(train_B))\n",
    "    train_batch = minibatchAB(gen_A, train_B, min(len(gen_A),len(train_B)))\n",
    "\n",
    "    \n",
    "    for i in range(n_generate):\n",
    "        next(train_batch)\n",
    "        _, A, B = train_batch.send(1)\n",
    "        \n",
    "        #showG(A,B)\n",
    "        showGen(A)\n",
    "        \n",
    "gen_A = load_data('../generation_images')[1:10]\n",
    "\n",
    "generate(gen_A,len(gen_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
